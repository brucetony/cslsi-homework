{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bruce Schultz; bschultz@uni-bonn.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ravinder Kaur; ravinder13kaur@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "testa = np.array([[0.70000, 0.70711], [0.70001, 0.70711]])\n",
    "\n",
    "def proj(u, v):\n",
    "    '''\n",
    "    Function that return the projection of v onto u\n",
    "    '''\n",
    "    return u*(np.dot(u, v)/np.dot(u, u))\n",
    "\n",
    "def CGS(A):\n",
    "    '''\n",
    "    Function using classical Gram-Schmidt Algorithm and returns Q and R\n",
    "    matrices.\n",
    "    '''\n",
    "    \n",
    "    R = np.zeros((len(A), len(A))) #Empty coefficient list\n",
    "    Q = np.zeros(np.shape(A)) #Empty Q matrix, same dim as input matrix\n",
    "    for j in range(len(A)): #For each vector in A\n",
    "        matrix_vec = A[:,j] # Define our vector\n",
    "        for i in range(j):\n",
    "            R[i, j] = np.dot(np.transpose(Q[i]), A[:,j])\n",
    "            matrix_vec = matrix_vec - R[i, j]*Q[:,i]\n",
    "        R[j, j] = np.linalg.norm(matrix_vec)\n",
    "        Q[:,j] = matrix_vec/R[j, j] #Insert orthonormal vec in Q matrix\n",
    "    \n",
    "    return Q, R\n",
    "    \n",
    "def MGS(A):\n",
    "    '''\n",
    "    Uses modified Gram-Schmidt algorithm to generate Q and R matrices from\n",
    "    input A matrix\n",
    "    '''\n",
    "    R = np.zeros((len(A), len(A))) #Empty coefficient list\n",
    "    Q = np.zeros(np.shape(A)) #Empty Q matrix, same dim as input matrix\n",
    "    for j in range(len(A)): #For each vector in A\n",
    "        matrix_vec = A[:,j] # Define our vector\n",
    "        for i in range(j):\n",
    "            R[i, j] = np.dot(np.transpose(Q[i]), matrix_vec)\n",
    "            matrix_vec = matrix_vec - R[i, j]*Q[:,i]\n",
    "        R[j, j] = np.linalg.norm(matrix_vec)\n",
    "        Q[:,j] = matrix_vec/R[j, j] #Insert orthonormal vec in Q matrix\n",
    "    \n",
    "    return Q, R\n",
    "\n",
    "def Householder(A):\n",
    "    \n",
    "    m, n = np.shape(A)\n",
    "    R = np.copy(A)\n",
    "    Qt = np.eye(A.shape[0])\n",
    "    for k in range(n):\n",
    "        matrix_vec = np.copy(R[k:,k])\n",
    "        basis_vec = np.zeros(len(matrix_vec)) #Standard basis vector\n",
    "        basis_vec[0] = 1 #Replace 0 with 1 are index position\n",
    "        sign = np.sign(matrix_vec[0])\n",
    "        ortho_vec = sign*np.linalg.norm(matrix_vec)*basis_vec+matrix_vec\n",
    "        ortho_vec = ortho_vec/np.linalg.norm(ortho_vec) #Normalize vector\n",
    "        difference = 2*np.dot(np.outer(ortho_vec,ortho_vec),(R[k:,k:])) #Maybe outer product?\n",
    "        R[k:,k:] = R[k:,k:] - difference\n",
    "        \n",
    "        #End Householder algorithm and now get Q\n",
    "        Qt[k:, k:] = Qt[k:, k:] - 2*np.dot(np.outer(ortho_vec,ortho_vec),(Qt[k:,k:]))\n",
    "    Qt = np.transpose(Qt)\n",
    "        \n",
    "    return Qt, R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "#b.)\n",
    "\n",
    "def QRerror(A, Q, R):\n",
    "    m, n = np.shape(A)\n",
    "    q_row, q_col = np.shape(Q)\n",
    "    qr_values = []\n",
    "    ortho_values = []\n",
    "    \n",
    "    qr_diff = A-Q*R\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            qr_values.append((qr_diff[i, j])**2)\n",
    "    qr_error = sum(qr_values)**0.5\n",
    "    \n",
    "    I = np.identity(q_row)\n",
    "    ortho_diff = np.transpose(Q)*Q-I\n",
    "    for g in range(q_row):\n",
    "        for h in range(q_col):\n",
    "            ortho_values.append((ortho_diff[i, j])**2)\n",
    "    ortho_error = sum(ortho_values)**0.5\n",
    "       \n",
    "    return qr_error, ortho_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single - CGS - Factorization Error =  0.860241980814\n",
      "Single - MGS - Factorization Error =  0.860241980814\n",
      "Single - Householder - Factorization Error =  0.995000346607\n",
      "Double - CGS - Factorization Error =  0.860241983297\n",
      "Double - MGS - Factorization Error =  0.860241983297\n",
      "Double - Householder - Factorization Error =  0.995000346608\n"
     ]
    }
   ],
   "source": [
    "#c.)   \n",
    "#Single Precision Floating Point Test\n",
    "testa = np.float32(testa)\n",
    "cgs_sing_q, cgs_sing_r = CGS(testa)\n",
    "mgs_sing_q, mgs_sing_r = MGS(testa)\n",
    "hh_sing_sing_q, hh_sing_sing_r = Householder(testa)\n",
    "cgs_sing_fac_error, cgs_sing_ortho = QRerror(testa, cgs_sing_q, cgs_sing_r)\n",
    "mgs_sing_fac_error, mgs_sing_ortho = QRerror(testa, mgs_sing_q, mgs_sing_r)\n",
    "hh_sing_fac_error, hh_sing_ortho = QRerror(testa, hh_sing_sing_q, hh_sing_sing_r)\n",
    "\n",
    "print(\"Single - CGS - Factorization Error = \", cgs_sing_fac_error)\n",
    "print(\"Single - MGS - Factorization Error = \", mgs_sing_fac_error)\n",
    "print(\"Single - Householder - Factorization Error = \", hh_sing_fac_error)\n",
    "\n",
    "#Double Precision Floating Point Test\n",
    "testa = np.float64(testa)\n",
    "cgs_doub_q, cgs_doub_r = CGS(testa)\n",
    "mgs_doub_q, mgs_doub_r = MGS(testa)\n",
    "hh_doub_sing_q, hh_doub_sing_r = Householder(testa)\n",
    "cgs_doub_fac_error, cgs_doub_ortho = QRerror(testa, cgs_doub_q, cgs_doub_r)\n",
    "mgs_doub_fac_error, mgs_doub_ortho = QRerror(testa, mgs_doub_q, mgs_doub_r)\n",
    "hh_doub_fac_error, hh_doub_ortho = QRerror(testa, hh_doub_sing_q, hh_doub_sing_r)\n",
    "\n",
    "print(\"Double - CGS - Factorization Error = \", cgs_doub_fac_error)\n",
    "print(\"Double - MGS - Factorization Error = \", mgs_doub_fac_error)\n",
    "print(\"Double - Householder - Factorization Error = \", hh_doub_fac_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single - CGS - Orthoganality Error =  1.00001432972\n",
      "Single - MGS - Orthoganality Error =  1.00001432972\n",
      "Single - Householder - Orthoganality Error =  1.0000143048\n",
      "Double - CGS - Orthoganality Error =  1.00001430481\n",
      "Double - MGS - Orthoganality Error =  1.00001430481\n",
      "Double - Householder - Orthoganality Error =  1.00001430501\n"
     ]
    }
   ],
   "source": [
    "print(\"Single - CGS - Orthoganality Error = \", cgs_sing_ortho)\n",
    "print(\"Single - MGS - Orthoganality Error = \", mgs_sing_ortho)\n",
    "print(\"Single - Householder - Orthoganality Error = \", hh_sing_ortho)\n",
    "print(\"Double - CGS - Orthoganality Error = \", cgs_doub_ortho)\n",
    "print(\"Double - MGS - Orthoganality Error = \", mgs_doub_ortho)\n",
    "print(\"Double - Householder - Orthoganality Error = \", hh_doub_ortho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of factorization errors, CGS and MGS were equivalent for both single and double precision floating point numbers. The Householder algorithm did a little bit worse in both cases than the Gram-Schmidt algorithms, though I believe it is because the algorithm is not working as intended. For the orthonality test, we want the value to be as close to 1 as possible and here the double precision floating point numbers performed better than their single counterparts except for Householder which did slightly worse (very slightly). When it is single, Householder did better than the CGS and MGS, but did worse in the double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single - CGS - Factorization Error =  0.0\n",
      "Single - MGS - Factorization Error =  0.0\n",
      "Single - Householder - Factorization Error =  0.0\n",
      "Double - CGS - Factorization Error =  9.83071796873e-11\n",
      "Double - MGS - Factorization Error =  9.83071796873e-11\n",
      "Double - Householder - Factorization Error =  9.83071796873e-11\n"
     ]
    }
   ],
   "source": [
    "#d.)\n",
    "\n",
    "def buildMatrix(m, n):\n",
    "    '''\n",
    "    Create a mxn matrix with random integers\n",
    "    '''\n",
    "    A = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            A[i, j] = random.randint(0, 20)\n",
    "    return A\n",
    "\n",
    "def diagS(m):\n",
    "    '''\n",
    "    Creates a mxm diaaonal matrix with values 2^(-i) for i 1:m\n",
    "    '''\n",
    "    S = np.zeros((m, m))\n",
    "    for i in range(m):\n",
    "        S[i, i] = 2**(-(i+1))\n",
    "    return S\n",
    "\n",
    "U, R = (np.linalg.qr(buildMatrix(80, 80)))\n",
    "V, R = (np.linalg.qr(buildMatrix(80, 80)))\n",
    "S = diagS(80)\n",
    "M = U*S*V\n",
    "N = np.float32(np.copy(M)) #Single\n",
    "\n",
    "#Single Precision\n",
    "cgs_n_q, cgs_n_r = CGS(N)\n",
    "mgs_n_q, mgs_n_r = MGS(N)\n",
    "hh_n_q, hh_n_r = Householder(N)\n",
    "cgs_n_fac_error, cgs_n_ortho = QRerror(N, cgs_n_q, cgs_n_r)\n",
    "mgs_n_fac_error, mgs_n_ortho = QRerror(N, mgs_n_q, mgs_n_r)\n",
    "hh_n_fac_error, hh_n_ortho = QRerror(N, hh_n_q, hh_n_r)\n",
    "\n",
    "print(\"Single - CGS - Factorization Error = \", cgs_n_fac_error)\n",
    "print(\"Single - MGS - Factorization Error = \", mgs_n_fac_error)\n",
    "print(\"Single - Householder - Factorization Error = \", hh_n_fac_error)\n",
    "\n",
    "#Double Precision\n",
    "cgs_m_q, cgs_m_r = CGS(M)\n",
    "mgs_m_q, mgs_m_r = MGS(M)\n",
    "hh_m_q, hh_m_r = Householder(M)\n",
    "cgs_m_fac_error, cgs_m_ortho = QRerror(N, cgs_m_q, cgs_m_r)\n",
    "mgs_m_fac_error, mgs_m_ortho = QRerror(N, mgs_m_q, mgs_m_r)\n",
    "hh_m_fac_error, hh_m_ortho = QRerror(N, hh_m_q, hh_m_r)\n",
    "\n",
    "print(\"Double - CGS - Factorization Error = \", cgs_m_fac_error)\n",
    "print(\"Double - MGS - Factorization Error = \", mgs_m_fac_error)\n",
    "print(\"Double - Householder - Factorization Error = \", hh_m_fac_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single - CGS - Orthoganality Error =  0.0\n",
      "Single - MGS - Orthoganality Error =  0.0\n",
      "Single - Householder - Orthoganality Error =  0.0\n",
      "Double - CGS - Orthoganality Error =  0.0\n",
      "Double - MGS - Orthoganality Error =  0.0\n",
      "Double - Householder - Orthoganality Error =  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Single - CGS - Orthoganality Error = \", cgs_n_ortho)\n",
    "print(\"Single - MGS - Orthoganality Error = \", mgs_n_ortho)\n",
    "print(\"Single - Householder - Orthoganality Error = \", hh_n_ortho)\n",
    "print(\"Double - CGS - Orthoganality Error = \", cgs_m_ortho)\n",
    "print(\"Double - MGS - Orthoganality Error = \", mgs_m_ortho)\n",
    "print(\"Double - Householder - Orthoganality Error = \", hh_m_ortho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment the matrix is much larger, though the correction to the MGS model is minor, it removes the smaller errors in the handling of floating point numbers and thus over time these errors do not accumulate as much as they do in the classical Gram-Schmidt algorithm. In the 2x2 instance, there are not enough calculations for errors to be introduced, therefore the two methods (CGS and MGS) are equivalent.\n",
    "\n",
    "That beings said, I do not know why I do not see a difference in my calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see attached images for this exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
